annotate("text", x=2010.5, y = 11.7, label = "Diabetes is\nincreasing!", family="xkcd" ) +
annotate("text", x=2024.5, y = 5.6, label = "Left of the dotted line \nare collected data\nright side are IDF predictions", family="xkcd" ) +
xkcdline(aes(xbegin=xbegin,ybegin=ybegin,xend=xend,yend=yend),datalines, xjitteramount = 0.12) +
geom_vline(xintercept=c(2013), linetype="dotted")
setwd("C:/Users/dsbmac/Documents/Professional Development/Getting and Cleaning Data/Quiz 3")
setwd("~/datasciencecoursera/getdata/quiz")
if (!file.exists("data")) {
dir.create("data")
}
## Question 1
url2 = "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url2, destfile = "./data/hid.csv")
hid = read.csv("./data/hid.csv")
str(hid)
# Create a logical vector that identifies the households on greater than 10 acres who sold more than $10,000 worth of agriculture products
agricultureLogical = (with(hid, ACR==3 & AGS==6))
str(agricultureLogical)
which(agricultureLogical)
## Question 2
# download the image
url1 = "http://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url1, destfile = "./data/jeff.jpg")
list.files("./data")
install.packages("jpeg")
library("jpeg")
# load the image
pic = readJPEG("./data/jeff.jpg", native = "TRUE")
head(pic)
summary(pic)
str(pic)
quantile(pic, probs = c(30, 50, 80)/100)
url3 = "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url4 = "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url3, destfile = "./data/gdp.csv")
download.file(url4, destfile = "./data/education.csv")
gdp = read.csv("./data/gdp.csv",skip=1)
edu = read.csv("./data/education.csv")
labels(gdp)
labels(edu)
gdp
str(gdp[100,1])
str(edu)
table(gdp$X, gdp$Gross.domestic.product.2012)
str(edu$CountryCode)
attributes(edu$CountryCode)
y = levels(edu$CountryCode)
str(gdp$X)
attributes(gdp$X)
x = levels(gdp$X)
# how many codes match
table(gdp$X %in% edu$CountryCode)
library(plyr)
#rename columns
gdp$X.8 = NULL
gdp$X.7 = NULL
gdp$X.6 = NULL
gdp$X.2 = NULL
gdp = rename(gdp, c(X="CountryCode", "GDP"="Rank", X.3= "Description", X.4="GDP", X.5="Extra"))
str(gdp)
table(x %in% y)
# sort
gdp[with(gdp, order(GDP)), ]
x = gdp[1:193,]
y = subset(edu, CountryCode != " ")
x
str(x)
str(y)
table(y$CountryCode %in% x$CountryCode)
order.gdp <- order(gdp$GDP)
order.gdp
head(gdp$GDP[order.gdp])
gdp[gdp$Rank,]
labels(edu)
levels(edu$Income.Group)
x = with(edu, CountryCode[Income.Group == "High income: nonOECD"])
highIncOECD = with(edu, CountryCode[Income.Group == "High income: OECD"])
check = sapply(gdp$CountryCode, function(a) a %in% x)
check2 = sapply(gdp$CountryCode, function(a) a %in% highIncOECD)
check2
gdp$check = check
gdp$check2 = check2
y = with(gdp, Rank[check])
y = with(gdp, Rank[check2])
y
y = as.matrix(y)
y = as.numeric(y)
class(y[1:1])
#recode missing values
y[y==""] <- NA
str(y)
# exclude missing vals from analysis
mean(y, na.rm=TRUE)
## Question 5
names(gdp)
url3 = "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url4 = "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url3, destfile = "./data/gdp.csv")
download.file(url4, destfile = "./data/education.csv")
gdp = read.csv("./data/gdp.csv",skip=1)
edu = read.csv("./data/education.csv")
labels(gdp)
labels(edu)
gdp
str(gdp[100,1])
str(edu)
table(gdp$X, gdp$Gross.domestic.product.2012)
str(edu$CountryCode)
attributes(edu$CountryCode)
y = levels(edu$CountryCode)
str(gdp$X)
attributes(gdp$X)
x = levels(gdp$X)
# how many codes match
table(gdp$X %in% edu$CountryCode)
#rename columns
gdp$X.8 = NULL
gdp$X.7 = NULL
gdp$X.6 = NULL
gdp$X.2 = NULL
gdp = rename(gdp, c(X="CountryCode", "GDP"="Rank", X.3= "Description", X.4="GDP", X.5="Extra"))
str(gdp)
table(x %in% y)
# sort
gdp[with(gdp, order(GDP)), ]
x = gdp[1:193,]
y = subset(edu, CountryCode != " ")
x
str(x)
str(y)
table(y$CountryCode %in% x$CountryCode)
order.gdp <- order(gdp$GDP)
order.gdp
head(gdp$GDP[order.gdp])
gdp[gdp$Rank,]
labels(edu)
levels(edu$Income.Group)
x = with(edu, CountryCode[Income.Group == "High income: nonOECD"])
highIncOECD = with(edu, CountryCode[Income.Group == "High income: OECD"])
check = sapply(gdp$CountryCode, function(a) a %in% x)
check2 = sapply(gdp$CountryCode, function(a) a %in% highIncOECD)
check2
gdp$check = check
gdp$check2 = check2
y = with(gdp, Rank[check])
y = with(gdp, Rank[check2])
y
y = as.matrix(y)
y = as.numeric(y)
class(y[1:1])
#recode missing values
y[y==""] <- NA
str(y)
# exclude missing vals from analysis
mean(y, na.rm=TRUE)
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
file.url <- 'http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
file.url <- 'http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
combined[with(combined, order(-V2) )]
combined[with(combined, order(-"V2") )]
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip=4, nrows=215))
dtGDP <- dtGDP[X != ""]
library(data.table)
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip=4, nrows=215))
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "gdp"))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
f <- file.path(getwd(), "EDSTATS_Country.csv")
download.file(url, f)
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
f <- file.path(getwd(), "EDSTATS_Country.csv")
download.file(url, f)
dtEd <- data.table(read.csv(f))
dt <- merge(dtGDP, dtEd, all=TRUE, by=c("CountryCode"))
sum(!is.na(unique(dt$rankingGDP)))
dt[order(rankingGDP, decreasing=TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, gdp)][13]
dt[, mean(rankingGDP, na.rm=TRUE), by=Income.Group]
breaks <- quantile(dt$rankingGDP, probs=seq(0, 1, 0.2), na.rm=TRUE)
dt$quantileGDP <- cut(dt$rankingGDP, breaks=breaks)
dt[Income.Group == "Lower middle income", .N, by=c("Income.Group", "quantileGDP")]
dt[, mean(rankingGDP, na.rm=TRUE), by=Income.Group]
require(knitr)
require(markdown)
packages <- c("data.table", "reshape2")
sapply(packages, library,
character.only=TRUE, quietly=TRUE)
packages <- c("data.table", "reshape2")
sapply(packages, require,
character.only=TRUE, quietly=TRUE)
setwd("~/datasciencecoursera/getdata/CourseProject")
setwd("~/datasciencecoursera/getdata/CourseProject")
path <- getwd()
path
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(path)) {dir.create(path)}
download.file(url, file.path(path, f))
pathIn <- file.path(path, "UCI HAR Dataset")
list.files(pathIn, recursive=TRUE)
dtSubjectTrain <- fread(file.path(pathIn, "train", "subject_train.txt"))
dtSubjectTest  <- fread(file.path(pathIn, "test" , "subject_test.txt" ))
fileToDataTable <- function (f) {
df <- read.table(f)
dt <- data.table(df)
}
dtTrain <- fileToDataTable(file.path(pathIn, "train", "X_train.txt"))
dtTest  <- fileToDataTable(file.path(pathIn, "test" , "X_test.txt" ))
# Read the subject files
dtSubjectTrain <- fileToDataTable(file.path(pathIn, "train", "subject_train.txt"))
dtSubjectTest  <- fileToDataTable(file.path(pathIn, "test" , "subject_test.txt" ))
# Read the activity files
dtActivityTrain <- fileToDataTable(file.path(pathIn, "train", "Y_train.txt"))
dtActivityTest  <- fileToDataTable(file.path(pathIn, "test" , "Y_test.txt" ))
# Read the data files
dtTrain <- fileToDataTable(file.path(pathIn, "train", "X_train.txt"))
dtTest  <- fileToDataTable(file.path(pathIn, "test" , "X_test.txt" ))
dtSubjectTrain <- dfread(file.path(pathIn, "train", "subject_train.txt"))
dtSubjectTrain <- fread(file.path(pathIn, "train", "subject_train.txt"))
dtSubject <- rbind(dtSubjectTrain, dtSubjectTest)
setnames(dtSubject, "V1", "subject")
dtActivity <- rbind(dtActivityTrain, dtActivityTest)
setnames(dtActivity, "V1", "activityNum")
dt <- rbind(dtTrain, dtTest)
dtFeatures <- dtFeatures[grepl("mean\\(\\)|std\\(\\)", featureName)]
# Merge columns
dtSubject <- cbind(dtSubject, dtActivity)
dt <- cbind(dtSubject, dt)
# Set key
setkey(dt, subject, activityNum)
# Extract only the mean and standard deviation
# What variable is what?
dtFeatures <- fread(file.path(pathIn, "features.txt"))
setnames(dtFeatures, names(dtFeatures), c("featureNum", "featureName"))
# Just mu and sd
dtFeatures <- dtFeatures[grepl("mean\\(\\)|std\\(\\)", featureName)]
dtFeatures$featureCode <- dtFeatures[, paste0("V", featureNum)]
head(dtFeatures)
dtFeatures$featureCode
dtActivityNames <- fread(file.path(pathIn, "activity_labels.txt"))
dtActivityNames <- fileToDataTable(file.path(pathIn, "activity_labels.txt"))
################################
### Instructions for project ###
################################
# You should create one R script called run_analysis.R that does the following.
#
#   1. Merges the training and the test sets to create one data set.
#   2. Extracts only the measurements on the mean and standard deviation for each measurement.
#   3. Uses descriptive activity names to name the activities in the data set.
#   4. Appropriately labels the data set with descriptive activity names.
#   5. Creates a second, independent tidy data set with the average of each variable
#       for each activity and each subject.
# Setup
# Load packages
packages <- c("data.table", "reshape2")
sapply(packages, require,
character.only=TRUE, quietly=TRUE)
# Set where
setwd("~/datasciencecoursera/getdata/CourseProject")
path <- getwd()
path
pathIn <- file.path(path, "UCI HAR Dataset")
list.files(pathIn, recursive=TRUE)
# Read the files
# Function to read then datatable
fileToDataTable <- function (f) {
df <- read.table(f)
dt <- data.table(df)
}
# Read the subject files
dtSubjectTrain <- fileToDataTable(file.path(pathIn, "train", "subject_train.txt"))
dtSubjectTest  <- fileToDataTable(file.path(pathIn, "test" , "subject_test.txt" ))
# Read the activity files
dtActivityTrain <- fileToDataTable(file.path(pathIn, "train", "Y_train.txt"))
dtActivityTest  <- fileToDataTable(file.path(pathIn, "test" , "Y_test.txt" ))
# Read the data files
dtTrain <- fileToDataTable(file.path(pathIn, "train", "X_train.txt"))
dtTest  <- fileToDataTable(file.path(pathIn, "test" , "X_test.txt" ))
# Merge the training and the test sets
# Concatenate the data tables
dtSubject <- rbind(dtSubjectTrain, dtSubjectTest)
setnames(dtSubject, "V1", "subject")
dtActivity <- rbind(dtActivityTrain, dtActivityTest)
setnames(dtActivity, "V1", "activityNum")
dt <- rbind(dtTrain, dtTest)
# Merge columns
dtSubject <- cbind(dtSubject, dtActivity)
dt <- cbind(dtSubject, dt)
# Set key
setkey(dt, subject, activityNum)
# Extract only the mu and sd
# What variable is what?
dtFeatures <- fread(file.path(pathIn, "features.txt"))
setnames(dtFeatures, names(dtFeatures), c("featureNum", "featureName"))
# Take jus mu and sd
dtFeatures <- dtFeatures[grepl("mean\\(\\)|std\\(\\)", featureName)]
# Vector of column names
dtFeatures$featureCode <- dtFeatures[, paste0("V", featureNum)]
# Subset using these names
select <- c(key(dt), dtFeatures$featureCode)
dt <- dt[, select, with=FALSE]
# Use descriptive activity names
# Read `activity_labels.txt` file
dtActivityNames <- fileToDataTable(file.path(pathIn, "activity_labels.txt"))
setnames(dtActivityNames, names(dtActivityNames), c("activityNum", "activityName"))
# Label with descriptive activity names
# Merge activity labels.
dt <- merge(dt, dtActivityNames, by="activityNum", all.x=TRUE)
# Add `activityName` as a key.
setkey(dt, subject, activityNum, activityName)
# Melt the data table to reshape it from a short and wide format to a tall and narrow format.
dt <- data.table(melt(dt, key(dt),
variable.name="featureCode"))
# Merge activity names
dt <- merge(dt, dtFeatures[, list(featureNum,
featureCode,
featureName)],
by="featureCode", all.x=TRUE)
#Create a new variable, `activity` that is equivalent to `activityName` as a factor class.
#Create a new variable, `feature` that is equivalent to `featureName` as a factor class.
dt$activity <- factor(dt$activityName)
dt$feature <- factor(dt$featureName)
# Seperate features from `featureName` using the helper function `grepthis`.
grepthis <- function (regex) {
grepl(regex, dt$feature)
}
# Features with 2 categories
n <- 2
y <- matrix(seq(1, n), nrow=n)
x <- matrix(c(grepthis("^t"), grepthis("^f")), ncol=nrow(y))
dt$featDomain <- factor(x %*% y, labels=c("Time", "Freq"))
x <- matrix(c(grepthis("Acc"), grepthis("Gyro")), ncol=nrow(y))
dt$featInstrument <- factor(x %*% y, labels=c("Accelerometer", "Gyroscope"))
x <- matrix(c(grepthis("BodyAcc"), grepthis("GravityAcc")), ncol=nrow(y))
dt$featAcceleration <- factor(x %*% y, labels=c(NA, "Body", "Gravity"))
x <- matrix(c(grepthis("mean()"), grepthis("std()")), ncol=nrow(y))
dt$featVariable <- factor(x %*% y, labels=c("Mean", "SD"))
## Features with 1 category
dt$featJerk <- factor(grepthis("Jerk"), labels=c(NA, "Jerk"))
dt$featMagnitude <- factor(grepthis("Mag"), labels=c(NA, "Magnitude"))
## Features with 3 categories
n <- 3
y <- matrix(seq(1, n), nrow=n)
x <- matrix(c(grepthis("-X"), grepthis("-Y"), grepthis("-Z")), ncol=nrow(y))
dt$featAxis <- factor(x %*% y, labels=c(NA, "X", "Y", "Z"))
# Check to make sure all possible combinations of `feature` are accounted for by all
#   possible combinations of the factor class variables.
r1 <- nrow(dt[, .N, by=c("feature")])
r2 <- nrow(dt[, .N, by=c("featDomain", "featAcceleration", "featInstrument", "featJerk", "featMagnitude", "featVariable", "featAxis")])
r1 == r2
# Create a tidy data set
# Create a data set with the average of each variable for each activity and each subject.
setkey(dt,
subject, activity, featDomain, featAcceleration, featInstrument, featJerk,
featMagnitude, featVariable, featAxis)
dtTidy <- dt[, list(count = .N, average = mean(value)), by=key(dt)]
# Make codebook.
knit("makeCodebook.Rmd", output="codebook.md", encoding="ISO8859-1", quiet=TRUE)
markdownToHTML("codebook.md", "codebook.html")
################################
### Instructions for project ###
################################
# You should create one R script called run_analysis.R that does the following.
#
#   1. Merges the training and the test sets to create one data set.
#   2. Extracts only the measurements on the mean and standard deviation for each measurement.
#   3. Uses descriptive activity names to name the activities in the data set.
#   4. Appropriately labels the data set with descriptive activity names.
#   5. Creates a second, independent tidy data set with the average of each variable
#       for each activity and each subject.
# Setup
# Load packages
packages <- c("data.table", "reshape2")
sapply(packages, require,
character.only=TRUE, quietly=TRUE)
# Set where
setwd("~/datasciencecoursera/getdata/CourseProject")
path <- getwd()
path
pathIn <- file.path(path, "UCI HAR Dataset")
list.files(pathIn, recursive=TRUE)
# Read the files
# Function to read then datatable
fileToDataTable <- function (f) {
df <- read.table(f)
dt <- data.table(df)
}
# Read the subject files
dtSubjectTrain <- fileToDataTable(file.path(pathIn, "train", "subject_train.txt"))
dtSubjectTest  <- fileToDataTable(file.path(pathIn, "test" , "subject_test.txt" ))
# Read the activity files
dtActivityTrain <- fileToDataTable(file.path(pathIn, "train", "Y_train.txt"))
dtActivityTest  <- fileToDataTable(file.path(pathIn, "test" , "Y_test.txt" ))
# Read the data files
dtTrain <- fileToDataTable(file.path(pathIn, "train", "X_train.txt"))
dtTest  <- fileToDataTable(file.path(pathIn, "test" , "X_test.txt" ))
# Merge the training and the test sets
# Concatenate the data tables
dtSubject <- rbind(dtSubjectTrain, dtSubjectTest)
setnames(dtSubject, "V1", "subject")
dtActivity <- rbind(dtActivityTrain, dtActivityTest)
setnames(dtActivity, "V1", "activityNum")
dt <- rbind(dtTrain, dtTest)
# Merge columns
dtSubject <- cbind(dtSubject, dtActivity)
dt <- cbind(dtSubject, dt)
# Set key
setkey(dt, subject, activityNum)
# Extract only the mu and sd
# What variable is what?
dtFeatures <- fread(file.path(pathIn, "features.txt"))
setnames(dtFeatures, names(dtFeatures), c("featureNum", "featureName"))
# Take jus mu and sd
dtFeatures <- dtFeatures[grepl("mean\\(\\)|std\\(\\)", featureName)]
# Vector of column names
dtFeatures$featureCode <- dtFeatures[, paste0("V", featureNum)]
# Subset using these names
select <- c(key(dt), dtFeatures$featureCode)
dt <- dt[, select, with=FALSE]
# Use descriptive activity names
# Read `activity_labels.txt` file
dtActivityNames <- fileToDataTable(file.path(pathIn, "activity_labels.txt"))
setnames(dtActivityNames, names(dtActivityNames), c("activityNum", "activityName"))
# Label with descriptive activity names
# Merge activity labels.
dt <- merge(dt, dtActivityNames, by="activityNum", all.x=TRUE)
# Add `activityName` as a key.
setkey(dt, subject, activityNum, activityName)
# Melt the data table to reshape it from a short and wide format to a tall and narrow format.
dt <- data.table(melt(dt, key(dt),
variable.name="featureCode"))
# Merge activity names
dt <- merge(dt, dtFeatures[, list(featureNum,
featureCode,
featureName)],
by="featureCode", all.x=TRUE)
#Create a new variable, `activity` that is equivalent to `activityName` as a factor class.
#Create a new variable, `feature` that is equivalent to `featureName` as a factor class.
dt$activity <- factor(dt$activityName)
dt$feature <- factor(dt$featureName)
# Seperate features from `featureName` using the helper function `grepthis`.
grepthis <- function (regex) {
grepl(regex, dt$feature)
}
# Features with 2 categories
n <- 2
y <- matrix(seq(1, n), nrow=n)
x <- matrix(c(grepthis("^t"), grepthis("^f")), ncol=nrow(y))
dt$featDomain <- factor(x %*% y, labels=c("Time", "Freq"))
x <- matrix(c(grepthis("Acc"), grepthis("Gyro")), ncol=nrow(y))
dt$featInstrument <- factor(x %*% y, labels=c("Accelerometer", "Gyroscope"))
x <- matrix(c(grepthis("BodyAcc"), grepthis("GravityAcc")), ncol=nrow(y))
dt$featAcceleration <- factor(x %*% y, labels=c(NA, "Body", "Gravity"))
x <- matrix(c(grepthis("mean()"), grepthis("std()")), ncol=nrow(y))
dt$featVariable <- factor(x %*% y, labels=c("Mean", "SD"))
## Features with 1 category
dt$featJerk <- factor(grepthis("Jerk"), labels=c(NA, "Jerk"))
dt$featMagnitude <- factor(grepthis("Mag"), labels=c(NA, "Magnitude"))
## Features with 3 categories
n <- 3
y <- matrix(seq(1, n), nrow=n)
x <- matrix(c(grepthis("-X"), grepthis("-Y"), grepthis("-Z")), ncol=nrow(y))
dt$featAxis <- factor(x %*% y, labels=c(NA, "X", "Y", "Z"))
# Check to make sure all possible combinations of `feature` are accounted for by all
#   possible combinations of the factor class variables.
r1 <- nrow(dt[, .N, by=c("feature")])
r2 <- nrow(dt[, .N, by=c("featDomain", "featAcceleration", "featInstrument", "featJerk", "featMagnitude", "featVariable", "featAxis")])
r1 == r2
# Create a tidy data set
# Create a data set with the average of each variable for each activity and each subject.
setkey(dt,
subject, activity, featDomain, featAcceleration, featInstrument, featJerk,
featMagnitude, featVariable, featAxis)
dtTidy <- dt[, list(count = .N, average = mean(value)), by=key(dt)]
f <- file.path(path, "HARUS_tidydata.txt")
write.table(dtTidy, f, quote=FALSE, sep="\t", row.names=FALSE)
# Make codebook.
knit("makeCodebook.Rmd", output="codebook.md", encoding="ISO8859-1", quiet=TRUE)
markdownToHTML("codebook.md", "codebook.html")
source("run_analysis.r")
setkey(dt,
