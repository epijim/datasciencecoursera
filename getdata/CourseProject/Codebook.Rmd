---
title: "Codebook"
author: "James Black"
date: "21 September 2014"
output:
  html_document:
    toc: true
    toc_depth: 2
---

Codebook was generated on `r as.character(Sys.time())` during the same process that generated the dataset. See `run_analysis.r`.

# Source

Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto. 
Smartlab - Non Linear Complex Systems Laboratory 
DITEN - UniversitÃƒ  degli Studi di Genova, Genoa I-16145, Italy. 
activityrecognition '@' smartlab.ws 
www.smartlab.ws 

# Methods for collection

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. 

# Attribute Information

For each record in the dataset it is provided: 
- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. 
- Triaxial Angular velocity from the gyroscope. 
- A 561-feature vector with time and frequency domain variables. 
- Its activity label. 
- An identifier of the subject who carried out the experiment.

#Citation Request:

> Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012

# Variable list and descriptions

Variable name    | Description
-----------------|------------
subject          | ID for subject
activity         | What activity
featDomain       | Time domain signal or frequency domain signal (Time or Freq)
featInstrument   | Measuring instrument (Accelerometer or Gyroscope)
featAcceleration | Acceleration signal (Body or Gravity)
featVariable     | Variable (Mean or SD)
featJerk         | Jerk signal
featMagnitude    | Magnitude of the signals calculated using the Euclidean norm
featAxis         | 3-axial signals in the X, Y and Z directions (X, Y, or Z)
featCount        | Count of data points used to compute `average`
featAverage      | Average of each variable for each activity and each subject

# The set up script

```{r runanalysis}
  setwd("~/datasciencecoursera/getdata/CourseProject")
  
  source("run_analysis.r", echo=T)
```

# Dataset structure

```{r}
str(dtTidy)
```

# Several rows

```{r}
head(dtTidy)
```

# Summary of the variables

```{r}
summary(dtTidy)
```


